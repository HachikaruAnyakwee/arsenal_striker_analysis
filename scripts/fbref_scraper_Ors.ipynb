{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hachikaruanyakwee/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data directory configuration\n",
    "DATA_DIR = \"data\"\n",
    "RAW_DATA_DIR = os.path.join(\"..\", DATA_DIR, \"raw\")\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#League configuration with proper naming\n",
    "LEAGUES = {\n",
    "    \"Big5_Europe\": \"https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats\",\n",
    "    \"Portugal\": \"https://fbref.com/en/comps/32/stats/Primeira-Liga-Stats#all_stats_standard\",\n",
    "    \"Turkey\": \"https://fbref.com/en/comps/26/stats/Super-Lig-Stats#all_stats_standard\",\n",
    "    \"Brazil\": \"https://fbref.com/en/comps/24/stats/Serie-A-Stats#all_stats_standard\",\n",
    "    \"Netherlands\": \"https://fbref.com/en/comps/23/stats/Eredivisie-Stats#all_stats_standard\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_stats_url(league_url):\n",
    "    \"\"\"Convert league URL to player stats URL\"\"\"\n",
    "    return league_url.replace(\"-Stats\", \"/stats/players/\") + \"-Stats\"\n",
    "\n",
    "def scrape_league_stats():\n",
    "    all_data = []\n",
    "    \n",
    "    for league_name, league_url in LEAGUES.items():\n",
    "        print(f\"\\nScraping {league_name}...\")\n",
    "        player_stats_url = get_player_stats_url(league_url)\n",
    "        \n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Request with timeout\n",
    "            response = requests.get(player_stats_url, headers=headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            table = soup.find('table', {'id': 'stats_standard'})\n",
    "            \n",
    "            if not table:\n",
    "                print(f\"Warning: Stats table not found at {player_stats_url}\")\n",
    "                continue\n",
    "                \n",
    "            # Proper HTML parsing to avoid FutureWarning\n",
    "            html_string = str(table)\n",
    "            df = pd.read_html(StringIO(html_string))[0]\n",
    "            \n",
    "            # Clean and standardize data\n",
    "            df.columns = df.columns.droplevel(0) if isinstance(df.columns, pd.MultiIndex) else df.columns\n",
    "            df['League'] = league_name\n",
    "            df['ScrapeDate'] = datetime.now().strftime('%Y-%m-%d')\n",
    "            \n",
    "            all_data.append(df)\n",
    "            print(f\"Success: Added {len(df)} players from {league_name}\")\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed for {league_name}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {league_name}: {str(e)}\")\n",
    "            \n",
    "        time.sleep(25 + abs(hash(league_name)) % 15)  # Randomized delay\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True) if all_data else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FBref scraping...\n",
      "\n",
      "Scraping Big5_Europe...\n",
      "Success: Added 2895 players from Big5_Europe\n",
      "\n",
      "Scraping Portugal...\n",
      "Warning: Stats table not found at https://fbref.com/en/comps/32/stats/Primeira-Liga/stats/players/#all_stats_standard-Stats\n",
      "\n",
      "Scraping Turkey...\n",
      "Warning: Stats table not found at https://fbref.com/en/comps/26/stats/Super-Lig/stats/players/#all_stats_standard-Stats\n",
      "\n",
      "Scraping Brazil...\n",
      "Warning: Stats table not found at https://fbref.com/en/comps/24/stats/Serie-A/stats/players/#all_stats_standard-Stats\n",
      "\n",
      "Scraping Netherlands...\n",
      "Warning: Stats table not found at https://fbref.com/en/comps/23/stats/Eredivisie/stats/players/#all_stats_standard-Stats\n",
      "\n",
      "Success! Saved data to ../data/raw/fbref_strikers_raw_20250408.csv\n",
      "Total players scraped: 2895\n",
      "\n",
      "League Distribution:\n",
      "League\n",
      "Big5_Europe    2895\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample Data:\n",
      "           Player    Pos        Squad       League\n",
      "0      Max Aarons     DF  Bournemouth  Big5_Europe\n",
      "1      Max Aarons  DF,MF     Valencia  Big5_Europe\n",
      "2  Rodrigo Abajas     DF     Valencia  Big5_Europe\n",
      "\n",
      "Execution time: 35.10 seconds\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    print(\"Starting FBref scraping...\")\n",
    "    \n",
    "    df = scrape_league_stats()\n",
    "    \n",
    "    if df is not None:\n",
    "        output_path = os.path.join(RAW_DATA_DIR, f\"fbref_strikers_raw_{datetime.now().strftime('%Y%m%d')}.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nSuccess! Saved data to {output_path}\")\n",
    "        print(f\"Total players scraped: {len(df)}\")\n",
    "        \n",
    "        # Basic data validation\n",
    "        print(\"\\nLeague Distribution:\")\n",
    "        print(df['League'].value_counts())\n",
    "        \n",
    "        print(\"\\nSample Data:\")\n",
    "        print(df[['Player', 'Pos', 'Squad', 'League']].head(3))\n",
    "    else:\n",
    "        print(\"\\nScraping failed - no data collected\")\n",
    "    \n",
    "    print(f\"\\nExecution time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
